---
Title: AI chatbots unable to accurately summarise news, BBC finds
URL: https://www.bbc.co.uk/news/articles/c0m17d8827ko
Author: Imran Rahman-Jones
Tags: ai
---

**Four major artificial intelligence (AI) chatbots are inaccurately summarising news stories, according to research carried out by the BBC.**

The BBC gave OpenAI's ChatGPT, Microsoft's Copilot, Google's Gemini and Perplexity AI content from the BBC website then asked them questions about the news.

It said the resulting answers contained "significant inaccuracies" and distortions.

[In a blog](https://www.bbc.co.uk/mediacentre/2025/articles/how-distortion-is-affecting-ai-assistants/), Deborah Turness, the CEO of BBC News and Current Affairs, said AI brought "endless opportunities" but the companies developing the tools were "playing with fire".

"We live in troubled times, and how long will it be before an AI-distorted headline causes significant real world harm?", she asked.

An OpenAI spokesperson said: "We support publishers and creators by helping 300 million weekly ChatGPT users discover quality content through summaries, quotes, clear links, and attribution."

The other tech companies which own the chatbots have been approached for comment. 

In [the study](https://www.bbc.co.uk/aboutthebbc/documents/bbc-research-into-ai-assistants.pdf), the BBC asked ChatGPT, Copilot, Gemini and Perplexity to summarise 100 news stories and rated each answer. 

It got journalists who were relevant experts in the subject of the article to rate the quality of answers from the AI assistants.

It found 51% of all AI answers to questions about the news were judged to have significant issues of some form.

Additionally, 19% of AI answers which cited BBC content introduced factual errors, such as incorrect factual statements, numbers and dates.

In her blog, Ms Turness said the BBC was seeking to "open up a new conversation with AI tech providers" so we can "work together in partnership to find solutions".

She called on the tech companies to "pull back" their AI news summaries, [as Apple did after complaints](https://www.bbc.co.uk/news/articles/cq5ggew08eyo) from the BBC that Apple Intelligence was misrepresenting news stories. 

Some examples of inaccuracies found by the BBC included: 

 * Gemini incorrectly said the NHS did not recommend vaping as an aid to quit smoking

* ChatGPT and Copilot said Rishi Sunak and Nicola Sturgeon were still in office even after they had left

* Perplexity misquoted BBC News in a story about the Middle East, saying Iran initially showed "restraint" and described Israel's actions as "aggressive"

In general, Microsoft's Copilot and Google's Gemini had more significant issues than OpenAI's ChatGPT and Perplexity, which counts Jeff Bezos as one of its investors. 

Normally, the BBC blocks its content from AI chatbots, but it opened its website up for the duration of the tests in December 2024.

The report said that as well as containing factual inaccuracies, the chatbots "struggled to differentiate between opinion and fact, editorialised, and often failed to include essential context".

The BBC's Programme Director for Generative AI, Pete Archer, said publishers "should have control over whether and how their content is used and AI companies should show how assistants process news along with the scale and scope of errors and inaccuracies they produce".

An OpenAI spokesperson told BBC News: "We've collaborated with partners to improve in-line citation accuracy and respect publisher preferences, including enabling how they appear in search by managing OAI-SearchBot in their robots.txt. We'll keep enhancing search results."

Robots.txt is an instruction in a web page's code which asks a bot not to use that page in search results.